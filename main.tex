%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass{article}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts, fancyhdr, color, comment, graphicx, environ}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{mdframed}
\usepackage{minted}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}

\pagestyle{fancy}
% Define problem environment
\newenvironment{problem}[2][Domanda]
    { \begin{mdframed}[backgroundcolor=gray!20] \textbf{#1 #2} \\}
    {  \end{mdframed}}

% Define solution environment
\newenvironment{solution}
    {\textit{Risposta:}}
    {}

\renewcommand{\qed}{\quad\qedsymbol}

% Prevent line break in inline mode
\binoppenalty=\maxdimen
\relpenalty=\maxdimen

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document information (author, course, date)
\lhead{Karina Chichifoi }
\rhead{\today} 
\chead{\textbf{Sistemi Operativi Q\&A}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Define huge title
\makeatletter
\newcommand\HUGE{\@setfontsize\Huge{30}{40}}
\makeatother
\begin{document}
% TITLEPAGE
\begin{titlepage}
	\centering
	\large
	A cura di Karina Chichifoi - Ultima revisione: \today
	
	\noindent\rule{15cm}{0.2pt}
	
	\vspace{1.5cm}
	
	\HUGE
	\textbf{SISTEMI OPERATIVI Q\&A}
	
	\vspace{1.5cm}
	
	\includegraphics[scale=0.6]{ab6.jpg}
	
	\vspace{1.5cm}
	
	\normalsize
	\url{https://github.com/TryKatChup/SistemiOperativi_QA}
	
	\clearpage
\end{titlepage}
% Premessa
\renewcommand{\abstractname}{}
\begin{abstract}
	\section*{Premessa}
	Ho scritto questo file in modo da facilitare lo studio e il superamento dell'esame di Sistemi Operativi T.
	Tuttavia è consigliato integrare questo materiale con le slide della professoressa Anna Ciampolini, disponibili sulla piattaforma \textit{Insegnamenti Online}.
		
	\section*{Contribuire alla guida}
	
	Se ritieni di poter migliorare la guida, oppure se sono state aggiunte altre domande al di fuori di questo file, o se hai trovato un errore, visita la repository GitHub ed apri una \textit{issue}, oppure inviami un messaggio. Ogni contributo è ben accetto :)
	
	\vspace{4mm}
	Link Repository: \url{https://github.com/TryKatChup?tab=repositories}
	
	\vspace{5mm}
	
	\begin{figure}[htb!]
		\centering
		\includegraphics[width=4cm]{qr.png}
		\caption{QR Code alla repository di GitHub}
	\end{figure}
\end{abstract}
\newpage
\begin{problem}{1}
Confrontare l’organizzazione monolitica con quella basata su microkernel.
\end{problem}
\begin{solution}
L’organizzazione monolitica (adottata da GNU/Linux) semplifica il sistema operativo, inglobandolo in un unico modulo contenente tutte le procedure, ognuna realizzante una funzione specifica.
\newline
In questo modello, i processi interagiscono tra loro per \textit{chiamate a procedura}, rendendo l’esecuzione più veloce, in quanto si evita di passare il controllo al sistema operativo.
\newline
\newline
Presenta diversi svantaggi: il sistema operativo è complesso e con questa organizzazione risulta:
\begin{itemize}
    \item Difficile da mantenere;
    \item Meno portabile;
    \item Meno efficiente.
\end{itemize}
Nel modello a microkernel il sistema operativo possiede un ridottissimo nucleo (\textit{kernel}) con poche funzionalità di base, e si interfaccia direttamente con l’hardware.
\newline
Il resto del sistema operativo è rappresentato da processi utente.
\newline
Questa struttura rende l’esecuzione più lenta poiché un processo deve attendere che il sistema operativo esegua una system call (procedura \textit{interna} al kernel) ma, allo stesso tempo, facilita la manutenzione e rende il sistema generalmente più sicuro.
\end{solution}
\begin{problem}{2}
Descrivere l'immagine di un processo nel SO Unix. 
\end{problem}
\begin{solution}
L’immagine di un processo è l’insieme delle aree di memoria e delle strutture dati ad esso dedicate. In Unix, le immagini sono divise in parti di tipologie diverse:
\begin{itemize}
    \item In base se è soggetto o meno a \textbf{swapping}:
    \begin{itemize}
        \item \emph{Swappable}: parte di immagine che può essere spostata in memoria secondaria per far posto ad altre parti di immagini.
        \item \emph{Non swappable}: parte di immagine che non può essere rimossa dalla memoria centrale poiché essenziale al funzionamento.
    \end{itemize}
    \item In base alla \textbf{accessibilità}:
    \begin{itemize}
        \item \emph{Kernel}: parte di immagine che viene eseguita solo dal sistema operativo in modalità kernel
        \item \emph{User}: parte di immagine eseguibile e modificabile dall’utente 
    \end{itemize}
\end{itemize}
L’immagine viene divisa in sotto parti:
\begin{itemize}
    \item \emph{Process structure}: contiene le informazioni per la gestione del processo (non swappable, kernel);
    \item \emph{User structure}: contiene le informazioni necessarie solo quando il processo è residente (swappable, kernel);
    \item \emph{Text structure}: contiene il riferimento alla memoria dove risiede il codice del processo (non swappable, kernel);
    \item \emph{Dati globali}: contiene le variabili globali del processo (swappable, user);
    \item \emph{Stack e Heap}: contengono dati dinamici associati al processo (swappable, user); 
    \item \emph{Stack del kernel}: contiene le system call associate al processo ed è interno al sistema (swappable, kernel).
\end{itemize}
\newpage
\end{solution}
\begin{problem}{3}
Il processo in Unix, caratteristiche e rappresentazione.
\end{problem}
\begin{solution}
Un processo è la minima unità di computazione.
\newline
In Unix viene definito \textit{pesante} (composto da un singolo task con un unico thread) e ha codice \textit{rientrante} (codice condivisibile da più processi, ma dati non condivisibili).
Per permettere la \textit{rientranza} i dati e il codice dei processi sono separati (modello a codice puro).
\newline
Nel proprio ciclo di vita, un processo può assumere più stati che ne indicano l’operazione effettuata: 
\begin{itemize}
    \item \emph{Init}: caricamento in memoria dell’immagine del processo;
    \item \emph{Ready}: processo pronto a essere eseguito;
    \item \emph{Running}: processo in esecuzione, utilizza la CPU;
    \item \emph{Sleeping}: il processo attende un evento per riprendere l’esecuzione; 
    \item \emph{Swapped}: una parte o tutto il processo è spostato in memoria secondaria;
    \item \emph{Zombie}: il processo ha concluso l'esecuzione, ma è in attesa che il proprio padre ne prelevi lo stato di terminazione;
    \item \emph{Terminated}: processo deallocato dalla memoria, fine del processo.
\end{itemize}
Un processo è rappresentato in Unix da diverse parti con relative proprietà:
\begin{itemize}
    \item \emph{Swappable}: parte di immagine che può essere spostata in memoria secondaria per far posto ad altre parti di immagini;
    \item \emph{Non swappable}: parte di immagine che non può essere rimossa dalla memoria centrale poiché essenziale al funzionamento; 
    \item \emph{Kernel}: parte di immagine che viene eseguita solo dal sistema operativo in modalità kernel;
    \item \emph{User}: parte di immagine eseguibile e modificabile dall’utente.
\end{itemize}
Il sistema operativo gestisce una struttura dati globale, chiamata \textit{text table}, in cui sono contenuti i puntatori ai codici utilizzati, eventualmente condivisi, dai processi. 
Ciascun elemento della text table viene chiamato \textit{text structure} e contiene un puntatore al codice e il numero dei processi che lo condividono.
\newline
\newline
Il \textit{Process Control Block} (PCB) è una struttura dati del nucleo del sistema operativo che contiene le informazioni necessarie per la gestione di un processo, ed è composto da:
\begin{itemize}
    \item \emph{Process structure}: contiene le informazioni necessarie al sistema per la gestione del processo, in particolare:
    \begin{itemize}
        \item id;
        \item stato;
        \item puntatori alle varie aree dati;
        \item riferimento all'elemento della text table associato al codice del processo;
        \item informazioni di scheduling.
    \end{itemize} 
    Più process structure costituiscono la \textit{process table}. 
    \item \emph{User structure}: contiene le informazioni necessarie solo se il processo è residente in memoria centrale, in particolare:
    \begin{itemize}
        \item Registri CPU;
        \item Informazioni sulle risorse allocate;
        \item Informazioni sulla gestione dei segnali;
        \item Ambiente del processo
    \end{itemize}
\end{itemize}
\end{solution}
\begin{problem}{4}
Descrivere i meccanismi del SO all’invocazione di system call.
\end{problem}
\begin{solution}
In Unix, per garantire protezione, si hanno due modalità: 
\begin{itemize}
    \item \emph{User Mode};
    \item \emph{Kernel Mode}.
\end{itemize}
Il sistema operativo esegue le system call in modalità \textit{kernel}. Quando si tenta di eseguire un’istruzione privilegiata, occorre cedere il controllo al sistema operativo.
\newline
Quando un processo tenta di eseguire un’istruzione privilegiata:
\begin{itemize}
    \item Viene inviata un’interruzione al sistema operativo; 
    \item Si salva lo stato del programma chiamante; 
    \item Si trasferisce il controllo al sistema operativo;
    \item Il sistema operativo esegue in modalità kernel l’istruzione richiesta; 
    \item Una volta completata la richiesta, il controllo viene passato nuovamente al programma chiamante, che continua a eseguire istruzioni in modalità user.
\end{itemize}
\end{solution}
\begin{problem}{5}
La comunicazione tra processi Unix.
\end{problem}
\begin{solution}
La comunicazione tra processi in Unix è vincolata dal fatto che i dati non sono condivisibili.
\newline
I processi, quindi, per comunicare tra loro possono ricorrere alla \textit{pipe}, un canale di comunicazione tra processi.
La pipe ha le seguenti caratteristiche:
\begin{itemize}
    \item Unidirezionale, accessibile da un lato di lettura e dall’altro di scrittura.
    \item Più processi della stessa famiglia possono spedire e ricevere messaggi attraverso la stessa pipe.
    \item Ha una capacità limitata, e i messaggi al suo interno vengono gestiti con politica \textit{FIFO} (First in-first out).
    \item La comunicazione tramite pipe risulta essere \textbf{asincrona}.
\end{itemize}
Per creare una pipe si utilizza la seguente primitiva:
\begin{center}
\texttt{int pipe(int fd[2]);}  
\end{center}
Dove \texttt{fd} è un puntatore a un vettore di 2 file descriptor:
\begin{itemize}
    \item \texttt{fd[0]} rappresenta il lato di lettura della pipe;
    \item \texttt{fd[1]} rappresenta il lato di scrittura della pipe.
\end{itemize}
La system call pipe restituisce 0 in caso di creazione della pipe con successo, -1 altrimenti.
\newline
Per accedere al lato di lettura della pipe viene utilizzata la system call \texttt{read}, per la scrittura viene utilizzata invece la system call \texttt{write}.
\newline
La comunicazione tramite \textit{pipe} presenta principalmente due svantaggi:
\begin{enumerate}
    \item La comunicazione avviene tra processi della stessa famiglia ;
    \item Non è persistente: viene distrutta quando terminano tutti i processi che la utilizzano.
\end{enumerate}
La comunicazione tra processi può avvenire anche tramite \textit{fifo}; ha le stesse funzioni della pipe, con il vantaggio che ha validità su tutti i processi in esecuzione sulla macchina.
\newpage
La fifo presenta le seguenti caratteristiche:
\begin{enumerate}
    \item Politica di gestione dei messaggi \textit{FIFO};
    \item È rappresentata da un file nel file system, quindi risulta persistente e visibile da tutti i processi;
    \item Ha un proprietario, un insieme di diritti e una lunghezza;
    \item È aperta e acceduta dalle system call dei file.
\end{enumerate}
La creazione della fifo avviene tramite la seguente system call:
\begin{center}
\texttt{int mkfifo(char* pathname, int mode)};
\end{center}
Dove \texttt{pathname} è il nome della fifo, \texttt{mode} esprime i permessi.
\end{solution}
\begin{problem}{6}
Descrivi la sincronizzazione tra processi in Unix 
\end{problem}
\begin{solution}
La sincronizzazione tra processi permette di imporre dei vincoli sulle operazioni di processi interagenti. In Unix, non essendoci condivisione di dati o variabili, risulta difficile imporre vincoli in base all'ordine cronologico delle azioni eseguite o in base alla mutua esclusione di una risorsa.
\newline
\newline
Il sistema operativo gestisce gli eventi asincroni tramite i \textit{segnali}, ovvero interruzioni asincrone per il processo che li riceve; possono avere origine sia software che hardware.
\newline
\newline
Il processo che riceve un segnale può decidere di:
\begin{itemize}
    \item gestirlo con una funzione di sistema (default) o con una funzione definita dal programmatore stesso (handler);
    \item ignorarlo, senza gestirlo.
\end{itemize}
Nel primo caso il processo, gestendo il segnale asincrono, interrompe la sua normale esecuzione e una volta terminata la gestione torna ad eseguire il suo codice dal punto in cui era stato interrotto.
\newline
Alcuni segnali sono \textit{non bloccabili}: non possono essere gestiti in modo personalizzato, ed è permessa solo l’operazione di default (SIGKILL, SIGSTOP).
\end{solution}
\begin{problem}{7}
Descrivere l'accesso e la gestione dei file da parte di processi Unix.
\end{problem}
\begin{solution}
L’accesso ai file nei sistemi UNIX è di tipo \textbf{sequenziale}.
L'I/O-Pointer registra di volta in volta la posizione corrente di lettura/scrittura nel file.
\newline
\newline
Unix mette a disposizione alcune strutture dati fondamentali per la gestione dei file:
\begin{itemize}
    \item \emph{Tabella dei file aperti di processo}: è una tabella situata nella user area di ogni processo, contiene una entry per ogni file aperto da quello specifico processo;
    \item \emph{Tabella dei file aperti di sistema}: è una tabella di sistema che contiene una entry per ogni file aperto, ma non ancora chiuso. Contiene anche l’IO-Pointer che indica la posizione corrente all’interno del file;
    \item \emph{Tabella dei file attivi}: è una tabella di sistema che contiene tutti i descrittori dei file aperti nel sistema (detti anche i-node) 
\end{itemize}
Quando un file viene aperto con \texttt{open()}:
\begin{enumerate}
    \item Viene inserito un nuovo elemento (file descriptor) all’interno della tabella dei file aperti di  processo nella prima posizione libera;
    \item Viene inserito un nuovo record nella tabella dei file aperti di sistema;
    \item Viene copiato l’i-node all’interno della tabella dei file attivi se il file non è già usato.
\end{enumerate}
Quando un file viene chiuso con \texttt{close()}:
\begin{enumerate}
    \item Viene eliminato l’elemento corrispondente al file descriptor nella tabella dei file aperti;
    \item Viene eliminato il corrispondente record nella tabella di file aperti di sistema (se il file non è condiviso con altri processi);
    \item Viene eliminato l’i-node nella tabella dei file attivi (se il file non è condiviso con altri processi).
\end{enumerate}
Quando viene effettuata una lettura/scrittura da/su file con \texttt{read()}/\texttt{write()}:
\begin{enumerate}
    \item Accesso al file tramite file descriptor;
    \item Attesa del completamento dell’operazione.
\end{enumerate}
\end{solution}
\begin{problem}{8}
Descrivere le tecniche di allocazione della memoria centrale.
\end{problem}
\begin{solution}
Esistono due metodi di allocazione di codice e dati di un processo in memoria centrale:
\begin{enumerate}
    \item Allocazione contigua;
    \item Allocazione non contigua.
\end{enumerate} 
L’allocazione \textit{contigua} presenta varie modalità:
\begin{itemize}
    \item \emph{A partizione singola}: la memoria è vista come un unico blocco all’interno del quale è possibile allocare un solo processo per volta, con totale mancanza di multiprogrammazione.
    \item \emph{A partizione multipla}: la memoria è suddivisa in più parti, dette partizioni, che possono avere dimensioni fisse o variabili:
    \begin{itemize}
        \item \emph{Fisse}: in ogni partizione vengono mappati processi in modo che una determinata partizione sia in grado di contenerli.
        \newline Si ha così il problema della frammentazione interna: tra le partizioni si vengono a creare spazi inutilizzati.
        \newline
        È presente un grado di multiprogrammazione limitato.
        \item \emph{Variabili}: ogni partizione avrà la dimensione del processo allocato.\newline Viene risolto così il problema della frammentazione interna e si ha una multiprogrammazione variabile.
        \newline È tuttavia presente il problema della frammentazione esterna, causata dall’allocazione di quantità di memoria maggiori di quelle effettivamente usate dai processi.
    \end{itemize}
\end{itemize}
L’allocazione \textit{non contigua} presenta diverse tecniche:
\begin{itemize}
    \item \emph{Paginazione}: suddivisione dello spazio fisico in pagine (frame) a dimensione costante, dove allocare parti di processi.
    \newline In questo modo viene risolto il problema della frammentazione esterna: a pagine logiche contigue corrispondono pagine fisiche non contigue.
    \newline
    Viene ridotto il problema della frammentazione interna, grazie alla dimensione fissa delle pagine.
    \item \emph{Segmentazione}: estende la tecnica di allocazione a partizioni variabili.
    \newline
    Lo spazio logico è suddiviso in segmenti caratterizzati da tipo e lunghezza del codice contenuto; ciascun segmento è rappresentato da un intero, che ne permette l'identificazione da parte del sistema operativo. 
    \newline
    Il problema principale della segmentazione, come nella tecnica a partizioni variabili è la frammentazione esterna; può essere risolto con la tecnica di allocazione best-fit, ovvero allocando un segmento solo a processi che più si avvicinano alle dimensioni di quest'ultimo.
    \item \emph{Segmentazione paginata}: è una combinazione tra segmentazione e paginazione. Lo spazio logico è diviso in segmenti e questi ultimi, a loro volta, in pagine.
    \newline Viene eliminata la frammentazione esterna, caricando in memoria solo le pagine necessarie.
\end{itemize}
\end{solution}
\begin{problem}{9}
Descrivere la paginazione.
\end{problem}
\begin{solution}
La paginazione consiste nel partizionamento dello spazio fisico di memoria in cornici (frame) di dimensione \textit{costante} e \textit{limitata} nelle quali mappare porzioni dei processi da allocare. Si ha una distinzione tra lo spazio fisico e quello logico: 
\begin{itemize}
    \item Fisico: costituito da frame, di dimensioni $D_f$ costanti e prefissate
    \item Logico: insieme di pagine di dimensione uguale a $D_f$. 
\end{itemize}
Ogni pagina logica viene mappata su una pagina fisica in memoria centrale.
\newline
L’indirizzo fisico ha la seguente struttura:
\begin{center}
\texttt{< f, d >}
\end{center}
Dove \texttt{f} è il numero di frame, mentre \texttt{d} è l’offset della cella rispetto l’inizio del frame.
\newline
\newline
L’indirizzo logico invece ha la seguente struttura:
\begin{center}
\texttt{< p, d >}
\end{center}
Dove \texttt{p} è il numero della pagina logica, mentre \texttt{d} è l’offset della cella rispetto l’inizio della pagina.
Gli spazi logici e fisici sono messi in relazione tra loro tramite il \textbf{binding}.
\newline
Quest’operazione associa a una pagina logica un frame fisico e tiene traccia di queste associazioni in ogni entry della tabella delle pagine, risiedente in memoria o nei registri della CPU.
\newline
La tabella delle pagine ha \textbf{dimensione fissa}, e non viene sempre utilizzata completamente.
\newline
Per distinguere gli elementi significativi da quelli non utilizzati si ricorre al bit di validità per ogni elemento della tabella che può assumere il valore:
\begin{itemize}
    \item 1: la entry è valida, quindi la pagina appartiene allo spazio logico del processo.
    \item 0: la entry non è valida.
\end{itemize}
Per riconoscere gli elementi significativi della tabella delle pagine viene utilizzato anche il \textbf{Page Table Legth Register}, che contiene il numero degli elementi validi nella tabella delle pagine.
I principali vantaggi di questa tecnica sono:
\begin{itemize}
    \item Eliminazione della frammentazione esterna poiché pagine logiche contigue possono essere mappate su frame fisici non contigui;
    \item Riduzione della frammentazione interna poiché limitata dalla dimensione dei frame.
    \item Possibilità di caricamento in memoria di un sottoinsieme delle pagine logiche di un processo.
\end{itemize}
Uno svantaggio è la complessità del codice che implementa il paging.
\end{solution}
\begin{problem}{10}
Descrivere la segmentazione.
\end{problem}
\begin{solution}
La segmentazione si basa sul partizionamento dello spazio logico degli indirizzi di un processo in parti (segmenti), ognuno caratterizzati da nome e lunghezza propri.
\newline
Ogni segmento è diviso per semantica (scopo del codice in esse contenuto) e a ciascuno è associato un intero per l’identificazione da parte del sistema operativo.
\newline
Ogni segmento è allocato in memoria in modo contiguo, ed è possibile applicare diritti di accesso specifici.
\newline
\newline
L’indirizzo logico è formato da:
\begin{itemize}
    \item Numero: identificativo del segmento
    \item Offset: identificativo della cella di memoria nel segmento
\end{itemize}
L’indirizzo fisico è invece formato da:
\begin{itemize}
    \item Base: indirizzo prima cella del segmento nello spazio fisico.
    \item Limite: dimensione del segmento.
\end{itemize}
Al fine di effettuare il binding tra indirizzo logico e fisico dei segmenti, viene utilizzata la \textbf{tabella dei segmenti} che risiede in memoria centrale per via delle sue elevate dimensioni (tabella globale).
\newline
Essendo la segmentazione un’estensione della tecnica di allocazione a partizioni variabili, presenta il problema della frammentazione esterna: può essere risolto grazie all’uso della tecnica di allocazione \emph{Best-Fit}, consistente nell’allocazione di un segmento nella porzione di memoria libera più vicina alle sue dimensioni. 
\newline
Questa tecnica potrebbe richiedere tempi elevati.
\end{solution}
\begin{problem}{11}
Descrivere la memoria virtuale.
\end{problem}
\begin{solution}
La dimensione della memoria centrale può rappresentare una restrizione per grado di multiprogrammazione e dimensione dei processi allocabili.
Questa restrizione non è più presente se si sfrutta la memoria virtuale: essa consente di gestire la memoria come se fosse virtualmente illimitata, consentendo l’esecuzione di processi non interamente allocabili in memoria centrale.
L’utilizzo della memoria virtuale risulta essere anche \textit{efficiente}, poichè il costo di caricamento di un processo e di swapping è limitato.
\newline
\newline
La memoria virtuale sfrutta la tecnica della paginazione su richiesta, effettuata dal \textit{pager}, che consiste nel caricare in memoria centrale dalla memoria secondaria solo le pagine del processo che sono necessarie alla sua esecuzione, sostituendo, man mano che l’esecuzione prosegue, le pagine non più utili con quelle attualmente necessarie.
\newline
Al fine di distinguere le pagine allocate in memoria centrale da quelle in memoria secondaria, il sistema si avvale di un \textbf{bit di validità} che, impostato a 1, indica la presenza della pagina in memoria centrale.
\newline
Nell’accesso ad ogni indirizzo di una pagina si consulta il suo bit di validità: se vale 1, allora il programma continua la propria esecuzione, ma, nel caso in cui valga 0, il programma manda un segnale al sistema operativo, che incaricherà il pager di allocare la pagina richiesta in un frame libero della memoria centrale.
\newline
Non sempre è presente spazio libero in memoria centrale: quando ciò accade è necessario scegliere una pagina da deallocare per far posto alla nuova pagina necessaria. 
\newline
Ci sono diversi algoritmi il cui scopo è capire quale pagina sia più corretto deallocare.
\begin{itemize}
    \item \emph{LFU} (Least Frequently Used): dealloca la pagina usata meno di frequente;
    \item \emph{FIFO}: dealloca la pagina caricata da più tempo;
    \item \emph{LRU} (Least Recently Used): dealloca la pagina usata meno di recente.
\end{itemize}
\end{solution}
\begin{problem}{12}
Descrivere le operazioni svolte dopo un Page Fault.
\end{problem}
\begin{solution}
Il Page Fault è un’interruzione di tipo trap che scatta nel momento in cui si sta cercando di accedere a una pagina che non è ancora stata caricata in memoria centrale, oppure quando si effettua un riferimento illegale.
\newline
Quando il sistema operativo riceve l’interruzione effettua i seguenti passaggi:
\begin{enumerate}
    \item Salva lo stato del contesto di esecuzione del processo;
    \item Verifica il motivo del Page Fault:
    \begin{itemize}
        \item Riferimento illegale: violazione delle politiche di protezione e terminazione del processo;
        \item Riferimento legale: la pagina è memorizzata in memoria secondaria.
    \end{itemize}
    \item Copia la pagina dalla memoria secondaria in un frame libero della memoria centrale; nel caso non si trovassero frame liberi si attuerebbe un algoritmo di sovrallocazione, individuando una pagina vittima ed effettuando la sostituzione)
    \item Aggiorna la tabella delle pagine;
    \item Ripristina il processo, che riparte dall’istruzione interrotta dal page fault.
\end{enumerate}
\end{solution}
\begin{problem}{13}
Descrivi la sovrallocazione e gli algoritmi di sostituzione.
\end{problem}
\begin{solution}
Il problema della sovrallocazione si presenta ogni volta che un processo tenta di accedere ad una pagina non caricata in memoria centrale e non ci sono pagine libere in quest’ultima dove allocare la pagina richiesta.
\newline
Per risolvere questo problema, si ricorre ad algoritmi di sostituzione, che hanno lo scopo di individuare una tra le tante pagine allocate in memoria centrale al fine di deallocarla, spostarla nella memoria secondaria e liberare spazio per la pagina necessaria.
\newline
Per rendere più efficiente il trattamento di un page fault in caso di sovrallocazione si introduce in ogni elemento della tabella delle pagine un \textbf{bit di modifica} (dirty bit):
\begin{itemize}
    \item Se il dirty bit vale 1, la pagina ha subito un aggiornamento da quando è stata caricata in memoria centrale. 
    \item Se il dirty bit vale 0, allora la pagina non è stata modificata.
\end{itemize}
Non sempre è necessario spostare la pagina individuata: nel caso in cui questa non sia stata modificata rispetto alla sua copia in memoria secondaria (dirty bit = 0), il sistema operativo può ridurre i tempi dell’operazione di sostituzione e decidere di eliminarla direttamente, senza doverla trasferire.
\newline
Ci sono diversi algoritmi il cui scopo è capire quale pagina sia la migliore da deallocare:
\begin{itemize}
    \item LFU (Least Frequently Used): dealloca la pagina usata meno di frequente.\newline
    Per questa tecnica è necessario introdurre un contatore, che tenga conto del numero di accessi per ogni pagina.
    \item FIFO: dealloca la pagina caricata da più tempo (indipendentemente dal suo uso).
In questo caso occorre memorizzare la cronologia dei caricamenti in memoria, o gestire una coda in cui ogni elemento rappresenta una pagina caricata in memoria.
    \item LRU (Least Recently Used): dealloca la pagina usata meno di recente.
\end{itemize}
Occorre memorizzare la sequenza degli accessi alle pagine in memoria; viene utilizzato o un time stamping per ciascun elemento della tabella delle pagine, che rappresenta l’istante dell’ultimo accesso in memoria, oppure uno stack, in cui il bottom rappresenta la pagina LRU.
\newline
La gestione, in entrambi i casi, risulta essere costosa.
\end{solution}
\begin{problem}{14}
Descrivere i metodi di accesso e di allocazione nel file system
\end{problem}
\begin{solution}
Il file system rappresenta la parte di sistema operativo che fornisce i meccanismi di accesso e memorizzazione delle informazioni in memoria secondaria.
\newline
Il file system realizza i concetti astratti di:
\begin{itemize}
    \item \emph{File}: unità logica di memorizzazione;
    \item \emph{Directory}: insieme di file e direttori;
    \item \emph{Partizione}: insieme di file associato ad un particolare dispositivo fisico.
\end{itemize}
Esistono diversi metodi di accesso messi a disposizione dal file system:
\begin{itemize}
    \item \emph{Sequenziale}: il file è visto come una sequenza di record logici e viene letto in modo sequenziale. Per accedere a un record bisogna prima accedere a tutti quelli che lo precedono. Ogni operazione di accesso (lettura/scrittura) posiziona il puntatore al file (che indica la posizione corrente all’interno del file) sull’elemento successivo a quello letto/scritto. 
    \item \emph{Diretto}: il file è visto come un insieme di record logici numerati e si accede specificando il numero del record a cui si vuole accedere.
    \item \emph{Ad indice}: a ogni file viene associata una struttura dati contenente l’indice delle informazioni contenute. Per accedere a un record si sfrutta la ricerca a indice, utilizzanod una chiave. 
\end{itemize} 
Sono presenti varie tecniche di allocazione nel file system:
\begin{itemize}
    \item  \emph{Allocazione contigua}: ogni file è mappato su un insieme di blocchi fisicamente contigui.
    \newline
    \newline
    Vantaggi:
    \begin{enumerate}
        \item possibilità di accedere sia in modo sequenziale che diretto;
        \item  basso costo sulla ricerca di un blocco.
    \end{enumerate}
    Svantaggi:
    \begin{enumerate}
        \item frammentazione esterna con necessità di compattazione (deframmentazione)
        \item aumento dinamico della dimensione di un file.
    \end{enumerate}
    \item \emph{Allocazione a lista concatenata}: i blocchi nei quali viene mappato ogni file sono organizzati in una lista concatenata.
    \newline
    \newline
  Vantaggi:
  \begin{enumerate}
      \item risolto il problema della frammentazione esterna;
      \item minor costo di allocazione.
  \end{enumerate}
  Svantaggi:
  \begin{enumerate}
      \item possibili errori in caso di link danneggiati;
      \item maggior occupazione a causa dei puntatori;
      \item alto costo nella ricerca.
  \end{enumerate}
  \item \emph{Allocazione a indice}: i puntatori ai blocchi in cui il file è mappato sono contenuti in un unico blocco (blocco a indice).
  \newline
  \newline
  Vantaggi:
  \begin{enumerate}
      \item risolto il problema della frammentazione esterna;
      \item minor costo di allocazione;
      \item accesso diretto;
      \item maggiore velocità di accesso.
  \end{enumerate}
  Svantaggi:
  \begin{enumerate}
      \item scarso utilizzo dei blocchi a indice in caso di file di piccole dimensioni.
  \end{enumerate}
\end{itemize} 
\end{solution}
\begin{problem}{15}
Descrivere l'organizzazione fisica del file system in Unix.
\end{problem}
\begin{solution}
In Unix tutto è rappresentato come file.
\newline
Questi vengono suddidisi in tre categorie: 
\begin{itemize}
    \item File ordinari (unità logica di memorizzazione);
    \item Directory (insieme di file e direttori);
    \item Dispositivi fisici.
\end{itemize}
A ogni file possono essere associati uno o più nomi simbolici ma un solo descrittore (i-node) identificato da un i-number (intero).
\newline
L’i-node contiene gli attributi dei file, come:
\begin{itemize}
    \item tipo di file;
    \item proprietario;
    \item data;
    \item numero di link.
\end{itemize}
La superficie del disco dove risiede il File System è partizionata in 4 blocchi:
\begin{itemize}
    \item \emph{Boot block}: blocco in cui è memorizzato il codice di avvio del sistema (bootstrap);
    \item \emph{Super block}: fornisce i limiti dei 4 blocchi e i puntatori alla lista dei blocchi e degli inode liberi;
    \item \emph{Data block}: l’area per la memorizzazione dei file;
    \item \emph{I-list}: contiene la lista di tutti gli i-node dei file nel File System. 
\end{itemize}
In Unix, l’allocazione dei file è realizzata con il metodo a indice.
\newline
Nell’i-node sono contenuti i puntatori ai blocchi di dati ed eventualmente ad altri blocchi indice (nel caso di file di elevate dimensioni); possono essere presenti più livelli di indirizzamento, ovvero i blocchi puntati possono contenere puntatori ad altri blocchi.
\newline
I direttori sono rappresentati come file e contengono un insieme di record logici composti dai file presenti nel direttorio.
\end{solution}
\begin{problem}{16}
Descrivi lo scheduling della CPU.
\end{problem}
\begin{solution}
Lo scheduling della CPU è il meccanismo mediante il quale il sistema operativo assegna l’uso della CPU a un processo, selezionandolo tra tutti i processi che si trovano nella coda ready (pronti a eseguire); questo compito è realizzato dallo \textbf{scheduler}.
\newline
\newline
Il \textbf{dispatcher} realizza il cambio di contesto (contest switch), ovvero il caricamento delle variabili locali di un processo che viene schedulato.
\newline
\newline
I processi nella ready queue che dovranno essere eseguiti verranno scelti in base a vari algoritmi di scheduling, principalmente divisi in due categorie:
\begin{enumerate}
    \item \emph{Algoritmi con prelazione} (pre-emptive): dopo un lasso di tempo fisso per tutti i processi, il sistema operativo può decidere di sottrarre la CPU al processo in esecuzione, assegnandola a un altro. Il processo passa così dallo stato di running allo stato ready.
    \newline
    I sistemi \textit{time-sharing} hanno sempre uno scheduling \textbf{pre-emptive}.
    
    \item \emph{Algoritmi senza prelazione} (non pre-emptive): Il sistema operativo non può attuare la sottrazione della CPU e deve aspettare la terminazione (o sospensione) dell’esecuzione del processo che la sta usando.
\end{enumerate}
Per classificare un algoritmo di scheduling bisogna tenere in considerazione alcune variabili.  L’obiettivo principale è quello di massimizzare: 
\begin{itemize}
    \item Utilizzo di CPU: percentuale media di utilizzo della CPU nell’unità di tempo;
    \item Throughput: numero di processi completati nell’unità di tempo.
\end{itemize}
Si vuole invece minimizzare:
\begin{itemize}
    \item Tempo di attesa: tempo totale trascorso nella coda dei processi pronti;
    \item Turnaround: tempo di esecuzione di un processo dall’assegnamento della CPU alla sua terminazione;
    \item Tempo di risposta: intervallo di tempo tra la sottomissione e l’inizio della prima risposta.
\end{itemize}
Gli algoritmi di scheduling sono ulteriormente suddivisi per la scelta del processo più opportuno da risvegliare:
\begin{itemize}
    \item \emph{FCFS} (First Come First Served): algoritmo senza prelazione con coda gestita in modo FIFO.
    \newline
    Non si può influire sull’ordine dei processi. Presenta un tempo di attesa alto se ci sono molti processi che usano in modo intensivo la CPU (CPU-bound).
    
    \item \emph{SJF} (Shortest Job First): tipicamente senza prelazione, viene effettuata una stima della lunghezza del prossimo CPU-burst per ogni processo e viene schedulato il processo con il CPU-burst minore.
    \newline
    A ogni processo viene assegnata una priorità (costante o variabile) e viene selezionato il processo con priorità maggiore.
    \newline
    È presente il rischio di \textbf{starvation} per processi con bassa priorità (uso intenso di CPU), dovuto alla costante presenza di processi con priorità minore.
    
    \item \emph{Round robin}: algoritmo con prelazione periodica, la CPU viene assegnata ciclicamente per un intervallo di tempo costante (time slicing).
    \newline
    Tipicamente usato nei sistemi timesharing.
    \newline
    Obiettivo principale è la minimizzazione del tempo di risposta.
    
    \item \emph{MLFQ} (Multiple Level Feedback Queues): effettivamente usato nei sistemi operativi.
    \newline
    Presenza di più code, ognuna delle quali ha una diversa priorità e viene gestita con un algoritmo di scheduling distinto.
    \newline
    I processi possono muoversi da una coda all’altra, in base alla loro storia:
    \begin{itemize}
        \item Da priorità bassa ad alta: processi in attesa da molto tempo;
        \item Da priorità alta a bassa: il processo è stato eseguito per molto tempo.
    \end{itemize}
\end{itemize} 
\end{solution}
\begin{problem}{17}
Descrivere i passaggi di sostituzione ed elaborazione nella Shell Bash.
\end{problem}
\begin{solution}
All’esecuzione di un file script contenente istruzioni eseguibili dalla bash shell, vengono effettuati i seguenti passaggi:
\begin{enumerate}
    \item Sostituzione dei comandi: i comandi contenuti tra backquote (\texttt{` `}) vengono eseguiti e sostituiti dal risultato prodotto;
    \item Sostituzione delle variabili e dei parametri: i nomi delle variabili (\texttt{\$nome}) sono espansi nei valori corrispondenti;
    \item  Sostituzione dei metacaratteri in nomi di file: i metacaratteri (caratteri speciali a multipla validità come \texttt{*}  \texttt{?}  \texttt{[ ]} ) vengono tradotti in nomi di file.
\end{enumerate}
In alcuni casi è necessario far sì che i caratteri speciali non vengano interpretati come tali. Per fare questo si utilizza:
\begin{itemize}
    \item \texttt{\textbackslash} (escape): il carattere che segue è considerato come un normale carattere;
    \item \texttt{‘ ‘} (apici singoli): proteggono da qualsiasi espansione;
    \item \texttt{“ ”} (apici doppi): proteggono dalle espansioni ad eccezione di \texttt{\$} \texttt{\textbackslash} \texttt{` `}
\end{itemize}
\end{solution}
\begin{problem}{18}
Descrivere i Monitor e variabili condizione.
\end{problem}
\begin{solution}
Il Monitor è un costrutto sintattico che associa un insieme di operazioni entry (o public) ad una struttura dati comune a più processi, ed è realizzato in modo tale che:
\begin{itemize}
    \item Le operazioni entry siano le uniche permesse sulla struttura;
    \item Le operazioni entry siano \textbf{mutuamente esclusive} e quindi un solo processo per volta può essere attivo sul monitor.
\end{itemize}
All’interno del monitor vengono dichiarate delle variabili locali che definiscono lo stato della risorsa e sono accessibili dall’interno del monitor o dall’esterno, solo da processi che utilizzano metodi entry.
\newline
Lo scopo del monitor è quello di controllare l’accesso alla risorsa da parte dei processi concorrenti.  
\newline
\newline
L’accesso alla risorsa avviene mediante due livelli di sincronizzazione:  
\begin{enumerate}
    \item Primo livello: garantisce la \textbf{mutua esclusione}, cioè un solo processo alla volta può avere accesso alle variabili del monitor. Se questo dovesse essere occupato, il processo viene sospeso nella entry queue. 
    \item Secondo livello: regola l’ordine di accesso al monitor. All' invocazione di una procedura viene controllato che la condizione di sincronizzazione sia soddisfatta, assicurandone l’ordinamento.
    \newline
    Se la condizione non è soddisfatta, il processo viene sospeso nella condition queue associata alla condizione.
    \newline
    La realizzazione avviene tramite la variabile \textit{condizione} (Condition) 
\end{enumerate}
La variabile condizione è necessaria solo all’interno del monitor e rappresenta la coda nella quale i processi sospendono la propria esecuzione.
\newline
Le operazioni che si possono effettuare sulle variabili condition sono:
\begin{itemize}
    \item \emph{wait (condition)}: sospende il processo e lo introduce nella coda individuata dalla variabile condition. Il monitor viene liberato. Al risveglio, il processo riacquisisce l’accesso mutualmente esclusivo al monitor e riprende l’esecuzione.
    \item \emph{signal (condition)}: riattiva il processo sospeso nella coda individuata dalla condition.\newline Non produce nessun effetto se non ci sono processi in coda.
\end{itemize}
\end{solution}
\begin{problem}{19}
Descrivi le operazioni e semantiche delle variabili condizione.
\end{problem}
\begin{solution}
Le variabili condizione sono particolari variabili situate all’interno di un monitor, un particolare costrutto sintattico che garantisce, grazie ai suoi metodi entry, la mutua esclusione su una risorsa condivisa.
\newline
La variabile condizione rappresenta una coda nella quale i processi vengono sospesi nel caso in cui l’accesso alla risorsa sia a loro negato.
\newline
\newline
Le possibili operazioni sulle variabili condizione sono: 
\begin{itemize}
    \item \texttt{await()}: sospende il processo e lo aggiunge nella coda individuata dalla variabile condizione;
    \item \texttt{signal()} / \texttt{signalAll()}: risveglia il primo processo/tutti i processi pronto/i nella coda individuata dalla condition.
\end{itemize}
\textbf{Semantiche:} 
\newline
Sia P un processo sospeso su una variabile condizione X e sia Q il processo che esegue la \texttt{signal()} su tale variabile. Come conseguenza della signal(), entrambi i processi potrebbero proseguire.
\newline
Ciò violerebbe la mutua esclusione del monitor: soltanto uno dei due processi può continuare a operare.
Le soluzioni per non violare la mutua esclusione sono:
\begin{enumerate}
    \item \emph{Signal and Wait}: prevede che il processo P risvegliato riprenda immediatamente la sua esecuzione e che Q venga sospeso affinché non possa cambiare la condizione di sincronizzazione (B). Questa semantica privilegia il processo segnalato rispetto al segnalante: ciò implica che il segnalato (P), proseguendo la sua esecuzione, \textit{è certo} di trovare vera la condizione per la quale è stato risvegliato.
    \newline
    \newline
    Lo schema tipico dell’invocazione di wait è, quindi, all’interno di un if:
    \begin{minted}{java}
    if (!B)
        cond.wait()
    // Accesso alla risorsa
    \end{minted}
    \item  \emph{Signal and Continue}: questa soluzione, a differenza della prima, privilegia il processo segnalante rispetto al segnalato. Il processo segnalante Q, dopo aver risvegliato P, prosegue la sua esecuzione mediante l’accesso esclusivo al monitor. Il processo P segnalato viene trasferito alla coda associata all’ingresso del monitor (entry-queue).
    \newline
    Poiché nella entry-queue possono esserci già altri processi, questi potrebbero precedere l’esecuzione di P e modificare il valore della condizione di sincronizzazione (B). 
    \newline
    P dovrà, pertanto, testare nuovamente la condizione di sincronizzazione prima di proseguire utilizzando un while():
    \begin{minted}{java}
    while (!B)
        cond.wait()
    //accesso alla risorsa
    \end{minted}
    \end{enumerate}
\end{solution}
\begin{problem}{20}
Esporre possibili soluzioni al problema della mutua esclusione.
\end{problem}
\begin{solution}
L’esigenza della mutua esclusione nasce quando più di un processo alla volta può avere accesso a variabili condivise e/o risorse comuni.
\newline
La mutua esclusione impone che le operazioni con le quali i processi accedono alle variabili comuni non si sovrappongano nel tempo.
\newline
Se un processo sta utilizzando una certa risorsa o sta accedendo a una variabile, questa non è accessibile a nessun altro processo \textbf{in tale istante di tempo}; di conseguenza l’operazione effettuata su tale risorsa o variabile si dice \textbf{atomica}.
\newline
\newline
La sequenza di istruzioni con cui un processo accede e modifica un insieme di variabili comuni prende il nome di sezione critica.
A ciascuna variabile interessata possono essere associate una o più sezioni critiche; la regola di mutua esclusione stabilisce che una sola sezione critica alla volta di una classe può essere in esecuzione in un determinato istante.
\newline
\newline
Per risolvere il problema della mutua esclusione:
\begin{enumerate}
    \item Le sezioni critiche della stessa classe devono essere eseguite in modo mutuamente esclusivo.
    \item Quando un processo si trova \textbf{all'esterno} della sezione critica non deve impedire agli altri processi l’accesso alla stessa sezione.
    \item Assenza di Deadlock.
\end{enumerate}
Lo schema generale di risoluzione della mutua esclusione è porre un prologo ed un epilogo rispettivamente all’inizio e alla fine della sezione critica.
\newline
Il prologo consiste nel chiedere l’autorizzazione ad ogni processo prima di entrare in una sezione critica, affinché venga garantito l’uso esclusivo della risorsa se questa è libera, oppure venga impedito l’acceso se questa è occupata. 
\newline
Nell’epilogo, invece, al completamento dell’azione il processo deve eseguire una sequenza di istruzioni per dichiarare libera la sezione critica. Le soluzioni possono essere:
\begin{itemize}
    \item \emph{Algoritmiche}: non si richiedono particolari meccanismi di sincronizzazione, si sfrutta la possibilità di condividere variabili che indicano lo stato della risorsa;
    \item \emph{Hardware-based}: supporto fornito direttamente dall’architettura hardware, come ad esempio la disabilitazione delle interruzioni;
    \item \emph{Software-based}: si utilizzano costrutti a livello software (come i semafori) per garantire la mutua esclusione.
\end{itemize}
\end{solution}
\begin{problem}{21}
Definizione e uso di semaforo.
\end{problem}
\begin{solution}
Il semaforo è uno strumento di sincronizzazione che consente di risolvere qualunque problema di sincronizzazione (come la mutua esclusione) tra thread nel modello ad ambiente globale.
\newline
Generalmente è realizzato dal nucleo del sistema operativo ed è un dato astratto rappresentato da un intero non negativo a cui è possibile accedere solo tramite le due operazioni, \texttt{p()} e \texttt{v()}:
\begin{itemize}
    \item \texttt{p(s)}: blocca il processo fino a che il valore del semaforo diventa $> 0$ e quindi decrementa tale valore di 1;
\begin{minted}{c}
    while(!s)
        s--;
    \end{minted}
    \item \texttt{v(s)}: incrementa di 1 il valore del semaforo.  
    \begin{minted}{c}
        s++;
    \end{minted}
\end{itemize}
Essendo entrambe le operazioni \textbf{atomiche} (eseguibili in un solo ciclo di clock), il valore del semaforo viene modificato da un solo processo alla volta.
Possiamo, quindi, avere due diversi funzionamenti:  
\begin{enumerate}
    \item \texttt{s = 0}: l’esecuzione di \texttt{p(s)} provoca l’attesa del processo che la invoca (semaforo rosso);
    \item \texttt{s > 0}: la chiamata di \texttt{p(s)} provoca il decremento di \texttt[s] e la continuazione dell’esecuzione (semaforo verde)
\end{enumerate}
Lo scopo dei semafori è quello di:
\begin{itemize}
    \item Eliminare qualsiasi forma di attesa attiva dei processi;
    \item Eliminare qualsiasi forma di Starvation: viene utilizzato un approccio FIFO per scegliere il processo da risvegliare.
\end{itemize}
\end{solution}
\begin{problem}{22}
Descrizione e confronto tra gestione a controllo di programma e gestione a interruzioni di dispositivi di I/O.
\end{problem}
\begin{solution}
Per gestire dispositivi di I/O vengono utilizzate interfacce, con il compito sia di mascherare la complessità della periferica (astrazione per l’utente), sia di garantire l’accesso alle periferiche e il loro funzionamento. 
Un altro compito del sottosistema di I/O è quello di naming, relativo alla definizione di uno spazio di nomi tramite i quali i singoli dispositivi vengono identificati univocamente dai processi che su essi devono operare.
\newline
Viene definito processo esterno un processo svolto da un’interfaccia fisica che opera in parallelo alla CPU, sui dispositivi di I/O, e come processo applicativo un processo in esecuzione dalla CPU, col compito di inviare comandi all’interfaccia di un dispositivo di I/O.
\newline
Normalmente, questo dispositivo è nello stato di stand-by, in attesa che il bit di start del proprio registro di controllo venga impostato a 1.
\newline
Una volta attivato, il dispositivo esegue il comando e, una volta completato, registra questo evento nel registro di stato ponendo a 1 il corrispondente bit di flag. Quindi riparte da capo rimettendosi in attesa.
\newline
\newline
\textbf{Gestione a controllo di programma}:
\begin{itemize}
    \item Esecuzione del processo esterno: Il processo esterno dell’interfaccia attende l’invio di un comando tramite il registro di controllo. Quando il bit di start in questo registro viene impostato a 1, il dispositivo esegue il comando inviato e segnala la sua fine tramite il registro di stato con un bit di flag a 1.
    \item Esecuzione del processo applicativo: il processo applicativo prepara il comando e lo invia impostando contemporaneamente il bit di start a 1; dopodichè attende la fine del comando, segnalato dal bit di flag con valore 1.
    \newline
    Tale schema risulta inappropriato per sistemi multiprogrammati a causa dei cicli di attesa attiva, nei quali i processi sono schedulati e utilizzano tempo utile della CPU.
\end{itemize}
\textbf{Gestione a interruzione}:
\newline
L’obiettivo è quello di risolvere il problema dell’attesa attiva.
\newline
In questa modalità di gestione, si riserva ad ogni dispositivo un semaforo: quando questo diventa verde, si attiva il dispositivo, abilitandolo a interrompere l’esecuzione della CPU (ponendo nel registro di controllo il bit di abilitazione a 1).
\newline
Quando si verifica la transizione del flag da zero a uno il controllore interrompe la CPU, che risponde con una funzione di gestione delle interruzioni del dispositivo.
\end{solution}
\end{document}